{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473a0134-e8c2-459b-94c1-64330403a6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#Detects emotions from text\n",
    "#Created by S. Biswas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed84f5c0-14ee-486e-8a34-ce5dd5939d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        sadness\n",
      "1        sadness\n",
      "2          anger\n",
      "3           love\n",
      "4          anger\n",
      "          ...   \n",
      "15995    sadness\n",
      "15996    sadness\n",
      "15997        joy\n",
      "15998      anger\n",
      "15999    sadness\n",
      "Name: Emotion, Length: 15999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.txt', sep=';', names=['Sentence', 'Emotion'], encoding='UTF8')\n",
    "#data cleaning\n",
    "df_train = df_train[df_train['Sentence'] != '']\n",
    "df_train = df_train.dropna()\n",
    "df_train = df_train.drop_duplicates()\n",
    "print(df_train['Emotion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f1b7e7-de1c-4fc0-b664-a2433cd3b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['length'] = [len(sen) for sen in df_train['Sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4d94c7-ef3b-4047-8f7c-9cc5b891acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        4\n",
      "1        4\n",
      "2        0\n",
      "3        3\n",
      "4        0\n",
      "        ..\n",
      "15995    4\n",
      "15996    4\n",
      "15997    2\n",
      "15998    0\n",
      "15999    4\n",
      "Name: Emotions, Length: 15999, dtype: int64\n",
      "0        sadness\n",
      "1        sadness\n",
      "2          anger\n",
      "3           love\n",
      "4          anger\n",
      "          ...   \n",
      "15995    sadness\n",
      "15996    sadness\n",
      "15997        joy\n",
      "15998      anger\n",
      "15999    sadness\n",
      "Name: Original_Emotion, Length: 15999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lb = LabelEncoder()\n",
    "df_train['Emotions'] = lb.fit_transform(df_train['Emotion'])\n",
    "print(df_train['Emotions'])\n",
    "df_train['Original_Emotion'] = lb.inverse_transform(df_train['Emotions'])\n",
    "print(df_train['Original_Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7f0a10-6b83-456b-83ca-3283d41c95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2f097f-b838-4b8e-a6f3-489e1203c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "df_train['Cleaned_Sentence'] = df_train['Sentence'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
    "df_train['Cleaned_Sentence'] = df_train['Cleaned_Sentence'].apply(lambda x: x.lower())\n",
    "df_train['Final_Cleaned_Sentence'] = df_train['Cleaned_Sentence'].apply(lambda x: ' '.join(stemmer.stem(word) for word in x.split() if word not in stopwords))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7d58df-d735-4f83-a673-bea51b72345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>length</th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Original_Emotion</th>\n",
       "      <th>Cleaned_Sentence</th>\n",
       "      <th>Final_Cleaned_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel Humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>didnt feel humili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>go feel hopeless damn hope around someon care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>im grab minut post feel greedi wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>love</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>ever feel nostalg fireplac know still properti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>anger</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>feel grouchi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Emotion  length  \\\n",
       "0                            i didnt feel Humiliated  sadness      23   \n",
       "1  i can go from feeling so hopeless to so damned...  sadness     108   \n",
       "2   im grabbing a minute to post i feel greedy wrong    anger      48   \n",
       "3  i am ever feeling nostalgic about the fireplac...     love      92   \n",
       "4                               i am feeling grouchy    anger      20   \n",
       "\n",
       "   Emotions Original_Emotion  \\\n",
       "0         4          sadness   \n",
       "1         4          sadness   \n",
       "2         0            anger   \n",
       "3         3             love   \n",
       "4         0            anger   \n",
       "\n",
       "                                    Cleaned_Sentence  \\\n",
       "0                            i didnt feel humiliated   \n",
       "1  i can go from feeling so hopeless to so damned...   \n",
       "2   im grabbing a minute to post i feel greedy wrong   \n",
       "3  i am ever feeling nostalgic about the fireplac...   \n",
       "4                               i am feeling grouchy   \n",
       "\n",
       "                              Final_Cleaned_Sentence  \n",
       "0                                  didnt feel humili  \n",
       "1  go feel hopeless damn hope around someon care ...  \n",
       "2               im grab minut post feel greedi wrong  \n",
       "3     ever feel nostalg fireplac know still properti  \n",
       "4                                       feel grouchi  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1d4d6e-edb5-4f02-be6c-c9d0ce48bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_train['Final_Cleaned_Sentence'], df_train['Emotion'], test_size= 0.2 , random_state=42 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb2c9ff4-14d0-47dc-af31-6bf9a568af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidfv = TfidfVectorizer()\n",
    "x_train_tfidf = tfidfv.fit_transform(x_train)\n",
    "x_test_tfidf = tfidfv.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23e9409-2471-4d73-ab2f-8bcf19d23f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====MultinomialNB======\n",
      "\n",
      "=====0.6590625======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.95      0.32      0.48       439\n",
      "        fear       0.88      0.23      0.37       375\n",
      "         joy       0.58      0.98      0.73      1027\n",
      "        love       1.00      0.03      0.05       303\n",
      "     sadness       0.72      0.91      0.80       950\n",
      "    surprise       1.00      0.02      0.04       106\n",
      "\n",
      "    accuracy                           0.66      3200\n",
      "   macro avg       0.85      0.42      0.41      3200\n",
      "weighted avg       0.76      0.66      0.59      3200\n",
      "=====\n",
      "=====SVC======\n",
      "\n",
      "=====0.815625======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.79      0.83       439\n",
      "        fear       0.84      0.73      0.78       375\n",
      "         joy       0.75      0.94      0.83      1027\n",
      "        love       0.82      0.37      0.51       303\n",
      "     sadness       0.87      0.90      0.89       950\n",
      "    surprise       0.82      0.47      0.60       106\n",
      "\n",
      "    accuracy                           0.82      3200\n",
      "   macro avg       0.83      0.70      0.74      3200\n",
      "weighted avg       0.82      0.82      0.80      3200\n",
      "=====\n",
      "=====RandomForestClassifier======\n",
      "\n",
      "=====0.8471875======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.80      0.86      0.83       439\n",
      "        fear       0.82      0.85      0.83       375\n",
      "         joy       0.84      0.90      0.87      1027\n",
      "        love       0.81      0.61      0.69       303\n",
      "     sadness       0.91      0.88      0.90       950\n",
      "    surprise       0.73      0.72      0.72       106\n",
      "\n",
      "    accuracy                           0.85      3200\n",
      "   macro avg       0.82      0.80      0.81      3200\n",
      "weighted avg       0.85      0.85      0.85      3200\n",
      "=====\n",
      "=====LogisticRegression======\n",
      "\n",
      "=====0.8240625======\n",
      "\n",
      "======              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.88      0.78      0.83       439\n",
      "        fear       0.85      0.72      0.78       375\n",
      "         joy       0.76      0.94      0.84      1027\n",
      "        love       0.83      0.46      0.59       303\n",
      "     sadness       0.88      0.92      0.90       950\n",
      "    surprise       0.74      0.46      0.57       106\n",
      "\n",
      "    accuracy                           0.82      3200\n",
      "   macro avg       0.82      0.71      0.75      3200\n",
      "weighted avg       0.83      0.82      0.82      3200\n",
      "=====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sauman/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "classifier = {\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'SVC':SVC(),\n",
    "    'RandomForestClassifier' : RandomForestClassifier(),\n",
    "    'LogisticRegression' : LogisticRegression(),   \n",
    "}\n",
    "for name, cls in classifier.items():\n",
    "    cls.fit(x_train_tfidf, y_train)\n",
    "    y_pred = cls.predict(x_test_tfidf)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"====={name}======\\n\")\n",
    "    print(f\"====={acc}======\\n\")\n",
    "    rep = classification_report(y_test, y_pred)\n",
    "    print(f\"======{rep}=====\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7105effe-7c10-47df-b2a9-e462c9a7da60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming stemmer and tfidfv are already defined and trained\u001b[39;00m\n\u001b[1;32m      2\u001b[0m lg \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m----> 3\u001b[0m lg\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train_tfidf\u001b[49m, y_train)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_data_for_predict\u001b[39m(text):\n\u001b[1;32m      6\u001b[0m     clean_text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^a-zA-Z]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming stemmer and tfidfv are already defined and trained\n",
    "lg = LogisticRegression()\n",
    "lg.fit(x_train_tfidf, y_train)\n",
    "\n",
    "def clean_data_for_predict(text):\n",
    "    clean_text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    t = clean_text.lower()  # Apply lowercasing on clean_text\n",
    "\n",
    "    # Ensure stemmer is called correctly\n",
    "    t = ' '.join(stemmer.stem(w) for w in t.split())\n",
    "    return t\n",
    "\n",
    "def predict_emotion(text):\n",
    "    text = clean_data_for_predict(text)\n",
    "    v = tfidfv.transform([text])  # Wrap text in a list to form a 2D array\n",
    "    \n",
    "    label = lg.predict(v)[0]  # Get the predicted label directly\n",
    "    emo = lb.inverse_transform(lg.predict(v))[0]\n",
    "    return emo, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef01a4aa-3090-47b3-98d1-251a9e8b6815",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: ['love']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI love you\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mpredict_emotion\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     15\u001b[0m v \u001b[38;5;241m=\u001b[39m tfidfv\u001b[38;5;241m.\u001b[39mtransform([text])  \u001b[38;5;66;03m# Wrap text in a list to form a 2D array\u001b[39;00m\n\u001b[1;32m     17\u001b[0m label \u001b[38;5;241m=\u001b[39m lg\u001b[38;5;241m.\u001b[39mpredict(v)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get the predicted label directly\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m emo \u001b[38;5;241m=\u001b[39m \u001b[43mlb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emo, label\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:161\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    159\u001b[0m diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msetdiff1d(y, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)))\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(diff))\n\u001b[1;32m    162\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[y]\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: ['love']"
     ]
    }
   ],
   "source": [
    "predict_emotion(\"I love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c81db3e-15f1-43c8-8870-4794b6503644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 12:11:34.864979: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-27 12:11:34.871619: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-27 12:11:34.954602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 12:11:36.621398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def cleaning_data(df, col, voc_size, max_len):\n",
    "    stemmer = PorterStemmer()\n",
    "    corpus = []\n",
    "    one_hot_code = []\n",
    "    for x in df[col]:\n",
    "        x = re.sub('[^a-zA-Z]', ' ', x)\n",
    "        x = x.lower()\n",
    "        x = x.split()\n",
    "        clean_words = []\n",
    "        for y in x:\n",
    "            if y not in stopwords:\n",
    "                clean_words.append(stemmer.stem(y))\n",
    "        corpus.append(' '.join(clean_words)) \n",
    "\n",
    "                \n",
    "    for line in corpus:       \n",
    "        encoded = one_hot(line, voc_size)\n",
    "        one_hot_code.append(encoded)\n",
    "\n",
    "    one_hot_code_padded = pad_sequences(one_hot_code, maxlen=max_len, padding='pre')\n",
    "    return one_hot_code_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f95a4c9-3436-4524-92a3-50f0db26cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ...  1892  3380  8217]\n",
      " [    0     0     0 ...  2494  1388   827]\n",
      " [    0     0     0 ...  3380  5490  4101]\n",
      " ...\n",
      " [    0     0     0 ... 11480   139 11504]\n",
      " [    0     0     0 ...  7044  9305  3795]\n",
      " [    0     0     0 ...  3380  1439  3781]]\n",
      "15999\n",
      "15999\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x_train = cleaning_data(df_train, 'Sentence', 12000, 3000)\n",
    "print(x_train)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(df_train['Emotion'])\n",
    "y_train = to_categorical(y_train_encoded)\n",
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b9fd8-4195-4846-8181-d97502471917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sauman/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15999\n",
      "15999\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 12:11:49.367869: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 191988000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2665s\u001b[0m 3s/step - accuracy: 0.5257 - loss: 1.2177\n",
      "Epoch 2/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2362s\u001b[0m 2s/step - accuracy: 0.9170 - loss: 0.2363\n",
      "Epoch 3/5\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2195s\u001b[0m 2s/step - accuracy: 0.9457 - loss: 0.1525\n",
      "Epoch 4/5\n",
      "\u001b[1m 491/1000\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m18:24\u001b[0m 2s/step - accuracy: 0.9610 - loss: 0.1080"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Dropout, LSTM, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Assuming y_train contains class labels (0-5 for 6 classes)\n",
    "# One-hot encode y_train if it is not already\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(df_train['Emotion'])\n",
    "y_train = to_categorical(y_train_encoded)  \n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=12000, output_dim=150, input_length=300))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128, return_sequences=True))  \n",
    "model.add(LSTM(64, return_sequences=False))  \n",
    "# model.add(Dense(64, activation='sigmoid')) \n",
    "model.add(Dense(6, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed06c1-6f08-45af-9a72-a5c2c65332b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae37a5-8f13-490b-94ee-81a78f3d45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
